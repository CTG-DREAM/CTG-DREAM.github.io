---
layout: post
title: Week 5
---

Week 5 – Week Beginning 9/24/2023:

I also capped the number of targets that can be active at any time. This ended up reducing the bunching of targets.
I updated the environment to function in Colab. It flickers a little bit, but I think it is because we are running a NN behind the scenes. All the troubleshooting recommendations only pertain to ensuring that the display is not updated twice per step… which is not the case.  Mostly so that I can test the simulation for a longer period of time with a TPU or GPU. My laptop does not have a GPU.
I updated the environment to allow for training without the display to minimize the RAM usage. Even so , Colab burns through the RAM fairly quickly… even in the high RAM instance. I think I can get ~ 35k steps (with two agents) before the instance expends the RAM. I want to circle back later and see if I can reduce complexity. Nothing immediately comes to mind other than the model itself.

The DQN agent is implemented and WAI.

Initial testing shows the agents are learning different behaviors that change over time. Sometimes an agent will converge quickly and other times it does not… overall these agents are not seeing a lot of experiences to begin with… only a 5-8k steps. I think it is promising as most simple models I’ve studied are closer to 10M
