---
layout: post
title: Week 4
---

Week 4 – Week Beginning 9/17/2023:

I worked on building out the initial DQN agent. The architecture of the model is:

    def dqn(self):
    
            model = Sequential([
                Conv2D(32,8, strides = 2, activation='relu', input_shape=(200,200,1)),
                Conv2D(64,4,strides = 2, activation='relu'),
                Conv2D(64,3,strides = 1, activation='relu'),
                Flatten(),
                Dense(self.action_space, activation='linear')
            ])
    
            model.compile(loss='mse', #'huber'
                          optimizer=tf.keras.optimizers.Adam(),
                          metrics=['MSE'])
            
            self.model = model

The agent is given a state space that is a 2d array based on its coverage range. Each target in this space, that is within the sensor’s field of view, is shown in the array as a 1. Empty space is represented as a 0.
Initial testing of this model showed that it is learning, but not as well as I had hoped. Digging into the model and results, I realized that I was not providing the correct 2d array to the model. I was providing a 100x100 array, but it should have been 200x200 based on the coverage range of 100. This will be corrected in the following week.
